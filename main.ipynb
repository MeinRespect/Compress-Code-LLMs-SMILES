{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets==2.16.1 (from -r SVD-LLM/requirements.txt (line 1))\n",
      "  Using cached datasets-2.16.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting numpy==1.26.3 (from -r SVD-LLM/requirements.txt (line 2))\n",
      "  Downloading numpy-1.26.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m801.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch>=2.0.1 (from -r SVD-LLM/requirements.txt (line 3))\n",
      "  Downloading torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting tqdm==4.65.0 (from -r SVD-LLM/requirements.txt (line 4))\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl.metadata (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m974.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting transformers==4.35.2 (from -r SVD-LLM/requirements.txt (line 5))\n",
      "  Downloading transformers-4.35.2-py3-none-any.whl.metadata (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece==0.1.99 (from -r SVD-LLM/requirements.txt (line 6))\n",
      "  Downloading sentencepiece-0.1.99-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting matplotlib==3.4.3 (from -r SVD-LLM/requirements.txt (line 7))\n",
      "  Downloading matplotlib-3.4.3.tar.gz (37.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.9/37.9 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: evaluate in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from -r SVD-LLM/requirements.txt (line 8)) (0.4.1)\n",
      "Requirement already satisfied: accelerate in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from -r SVD-LLM/requirements.txt (line 9)) (0.21.0)\n",
      "Requirement already satisfied: filelock in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from datasets==2.16.1->-r SVD-LLM/requirements.txt (line 1)) (3.9.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from datasets==2.16.1->-r SVD-LLM/requirements.txt (line 1)) (15.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from datasets==2.16.1->-r SVD-LLM/requirements.txt (line 1)) (0.6)\n",
      "Collecting dill<0.3.8,>=0.3.0 (from datasets==2.16.1->-r SVD-LLM/requirements.txt (line 1))\n",
      "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: pandas in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from datasets==2.16.1->-r SVD-LLM/requirements.txt (line 1)) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from datasets==2.16.1->-r SVD-LLM/requirements.txt (line 1)) (2.28.2)\n",
      "Requirement already satisfied: xxhash in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from datasets==2.16.1->-r SVD-LLM/requirements.txt (line 1)) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from datasets==2.16.1->-r SVD-LLM/requirements.txt (line 1)) (0.70.16)\n",
      "Collecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.16.1->-r SVD-LLM/requirements.txt (line 1))\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: aiohttp in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from datasets==2.16.1->-r SVD-LLM/requirements.txt (line 1)) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from datasets==2.16.1->-r SVD-LLM/requirements.txt (line 1)) (0.21.4)\n",
      "Collecting packaging (from datasets==2.16.1->-r SVD-LLM/requirements.txt (line 1))\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pyyaml>=5.1 (from datasets==2.16.1->-r SVD-LLM/requirements.txt (line 1))\n",
      "  Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from transformers==4.35.2->-r SVD-LLM/requirements.txt (line 5)) (2023.12.25)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.35.2->-r SVD-LLM/requirements.txt (line 5))\n",
      "  Downloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from transformers==4.35.2->-r SVD-LLM/requirements.txt (line 5)) (0.4.2)\n",
      "Collecting cycler>=0.10 (from matplotlib==3.4.3->-r SVD-LLM/requirements.txt (line 7))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib==3.4.3->-r SVD-LLM/requirements.txt (line 7))\n",
      "  Downloading kiwisolver-1.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from matplotlib==3.4.3->-r SVD-LLM/requirements.txt (line 7)) (10.2.0)\n",
      "Collecting pyparsing>=2.2.1 (from matplotlib==3.4.3->-r SVD-LLM/requirements.txt (line 7))\n",
      "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting python-dateutil>=2.7 (from matplotlib==3.4.3->-r SVD-LLM/requirements.txt (line 7))\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from torch>=2.0.1->-r SVD-LLM/requirements.txt (line 3)) (4.8.0)\n",
      "Requirement already satisfied: sympy in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from torch>=2.0.1->-r SVD-LLM/requirements.txt (line 3)) (1.12)\n",
      "Collecting networkx (from torch>=2.0.1->-r SVD-LLM/requirements.txt (line 3))\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jinja2 (from torch>=2.0.1->-r SVD-LLM/requirements.txt (line 3))\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.0.1->-r SVD-LLM/requirements.txt (line 3))\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.0.1->-r SVD-LLM/requirements.txt (line 3))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.0.1->-r SVD-LLM/requirements.txt (line 3))\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.1->-r SVD-LLM/requirements.txt (line 3))\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.0.1->-r SVD-LLM/requirements.txt (line 3))\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.0.1->-r SVD-LLM/requirements.txt (line 3))\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.0.1->-r SVD-LLM/requirements.txt (line 3))\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.0.1->-r SVD-LLM/requirements.txt (line 3))\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.0.1->-r SVD-LLM/requirements.txt (line 3))\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.0.1->-r SVD-LLM/requirements.txt (line 3))\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.0.1->-r SVD-LLM/requirements.txt (line 3))\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.0.0 (from torch>=2.0.1->-r SVD-LLM/requirements.txt (line 3))\n",
      "  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.1->-r SVD-LLM/requirements.txt (line 3))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: responses<0.19 in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from evaluate->-r SVD-LLM/requirements.txt (line 8)) (0.18.0)\n",
      "Collecting psutil (from accelerate->-r SVD-LLM/requirements.txt (line 9))\n",
      "  Downloading psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from aiohttp->datasets==2.16.1->-r SVD-LLM/requirements.txt (line 1)) (1.3.1)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets==2.16.1->-r SVD-LLM/requirements.txt (line 1))\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from aiohttp->datasets==2.16.1->-r SVD-LLM/requirements.txt (line 1)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from aiohttp->datasets==2.16.1->-r SVD-LLM/requirements.txt (line 1)) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from aiohttp->datasets==2.16.1->-r SVD-LLM/requirements.txt (line 1)) (1.9.4)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib==3.4.3->-r SVD-LLM/requirements.txt (line 7))\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.19.0->datasets==2.16.1->-r SVD-LLM/requirements.txt (line 1))\n",
      "  Downloading charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.19.0->datasets==2.16.1->-r SVD-LLM/requirements.txt (line 1))\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1 (from requests>=2.19.0->datasets==2.16.1->-r SVD-LLM/requirements.txt (line 1))\n",
      "  Downloading urllib3-1.26.19-py2.py3-none-any.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting certifi>=2017.4.17 (from requests>=2.19.0->datasets==2.16.1->-r SVD-LLM/requirements.txt (line 1))\n",
      "  Using cached certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=2.0.1->-r SVD-LLM/requirements.txt (line 3))\n",
      "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets==2.16.1->-r SVD-LLM/requirements.txt (line 1))\n",
      "  Downloading multiprocess-0.70.15-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from pandas->datasets==2.16.1->-r SVD-LLM/requirements.txt (line 1)) (2023.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from sympy->torch>=2.0.1->-r SVD-LLM/requirements.txt (line 3)) (1.3.0)\n",
      "Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.1.99-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl (797.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.3/797.3 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.7/757.7 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.15-py311-none-any.whl (135 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (290 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.5/290.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "Downloading charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (140 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.3/140.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
      "Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading urllib3-1.26.19-py2.py3-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: matplotlib\n",
      "  Building wheel for matplotlib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for matplotlib: filename=matplotlib-3.4.3-cp311-cp311-linux_x86_64.whl size=7221524 sha256=50398c18a0148ccc3e8a01cb9899bf2a1e8ba1f447ff921bfaeb8427007aa690\n",
      "  Stored in directory: /cephfs/projects/ppashin/.cache/pip/wheels/5a/99/fa/d6b0fc4a7c0f444b5f0ee8e7513f1d3095338bc1b458033e5d\n",
      "Successfully built matplotlib\n",
      "Installing collected packages: sentencepiece, urllib3, triton, tqdm, six, pyyaml, pyparsing, psutil, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, kiwisolver, idna, fsspec, dill, cycler, charset-normalizer, certifi, attrs, python-dateutil, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, jinja2, nvidia-cusolver-cu12, matplotlib, torch, tokenizers, transformers, datasets\n",
      "  Attempting uninstall: sentencepiece\n",
      "    Found existing installation: sentencepiece 0.2.0\n",
      "    Uninstalling sentencepiece-0.2.0:\n",
      "      Successfully uninstalled sentencepiece-0.2.0\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.0.0\n",
      "    Uninstalling triton-2.0.0:\n",
      "      Successfully uninstalled triton-2.0.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.2.0\n",
      "    Uninstalling fsspec-2024.2.0:\n",
      "      Successfully uninstalled fsspec-2024.2.0\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.8\n",
      "    Uninstalling dill-0.3.8:\n",
      "      Successfully uninstalled dill-0.3.8\n",
      "  Attempting uninstall: multiprocess\n",
      "    Found existing installation: multiprocess 0.70.16\n",
      "    Uninstalling multiprocess-0.70.16:\n",
      "      Successfully uninstalled multiprocess-0.70.16\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.0\n",
      "    Uninstalling torch-2.0.0:\n",
      "      Successfully uninstalled torch-2.0.0\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.3\n",
      "    Uninstalling tokenizers-0.13.3:\n",
      "      Successfully uninstalled tokenizers-0.13.3\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.31.0\n",
      "    Uninstalling transformers-4.31.0:\n",
      "      Successfully uninstalled transformers-4.31.0\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.18.0\n",
      "    Uninstalling datasets-2.18.0:\n",
      "      Successfully uninstalled datasets-2.18.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gdown 5.1.0 requires beautifulsoup4, which is not installed.\n",
      "scikit-learn 1.4.1.post1 requires joblib>=1.2.0, which is not installed.\n",
      "scikit-learn 1.4.1.post1 requires scipy>=1.6.0, which is not installed.\n",
      "scikit-learn 1.4.1.post1 requires threadpoolctl>=2.0.0, which is not installed.\n",
      "hyperopt 0.2.7 requires scipy, which is not installed.\n",
      "autogluon-multimodal 1.0.0 requires defusedxml<0.7.2,>=0.7.1, which is not installed.\n",
      "autogluon-multimodal 1.0.0 requires jsonschema<4.18,>=4.14, which is not installed.\n",
      "autogluon-multimodal 1.0.0 requires scipy<1.13,>=1.5.4, which is not installed.\n",
      "shap 0.45.0 requires scipy, which is not installed.\n",
      "statsmodels 0.14.0 requires scipy!=1.9.2,>=1.4, which is not installed.\n",
      "ray 2.6.3 requires jsonschema, which is not installed.\n",
      "lightning-cloud 0.5.64 requires pyjwt, which is not installed.\n",
      "lightning-cloud 0.5.64 requires websocket-client, which is not installed.\n",
      "blessed 1.20.0 requires wcwidth>=0.1.4, which is not installed.\n",
      "sphinx 7.2.6 requires babel>=2.9, which is not installed.\n",
      "sphinx 7.2.6 requires Pygments>=2.14, which is not installed.\n",
      "lightning 2.0.9.post0 requires beautifulsoup4<6.0,>=4.8.0, which is not installed.\n",
      "lightning 2.0.9.post0 requires traitlets<7.0,>=5.3.0, which is not installed.\n",
      "lightning 2.0.9.post0 requires websocket-client<3.0, which is not installed.\n",
      "statsforecast 1.4.0 requires scipy>=1.7.3, which is not installed.\n",
      "autogluon-timeseries 1.0.0 requires joblib<2,>=1.1, which is not installed.\n",
      "autogluon-timeseries 1.0.0 requires scipy<1.13,>=1.5.4, which is not installed.\n",
      "optuna 3.5.0 requires alembic>=1.5.0, which is not installed.\n",
      "optuna 3.5.0 requires sqlalchemy>=1.3.0, which is not installed.\n",
      "lightgbm 3.2.1 requires scipy, which is not installed.\n",
      "autowoe 1.3.2 requires joblib, which is not installed.\n",
      "autowoe 1.3.2 requires scipy, which is not installed.\n",
      "autowoe 1.3.2 requires seaborn, which is not installed.\n",
      "lightautoml 0.3.8.1 requires joblib<1.3.0, which is not installed.\n",
      "lightautoml 0.3.8.1 requires seaborn, which is not installed.\n",
      "nltk 3.8.1 requires joblib, which is not installed.\n",
      "scikit-image 0.20.0 requires scipy>=1.8; python_version > \"3.9\", which is not installed.\n",
      "fastai 2.7.14 requires scipy, which is not installed.\n",
      "autogluon-core 1.0.0 requires scipy<1.13,>=1.5.4, which is not installed.\n",
      "catboost 1.2.3 requires scipy, which is not installed.\n",
      "autogluon-tabular 1.0.0 requires scipy<1.13,>=1.5.4, which is not installed.\n",
      "autogluon-features 1.0.0 requires pandas<2.2.0,>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n",
      "autogluon-multimodal 1.0.0 requires pandas<2.2.0,>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n",
      "autogluon-multimodal 1.0.0 requires torch<2.1,>=2.0, but you have torch 2.4.0 which is incompatible.\n",
      "autogluon-multimodal 1.0.0 requires transformers[sentencepiece]<4.32.0,>=4.31.0, but you have transformers 4.35.2 which is incompatible.\n",
      "autogluon-timeseries 1.0.0 requires pandas<2.2.0,>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n",
      "autogluon-timeseries 1.0.0 requires torch<2.1,>=2.0, but you have torch 2.4.0 which is incompatible.\n",
      "torchvision 0.15.2 requires torch==2.0.1, but you have torch 2.4.0 which is incompatible.\n",
      "lightautoml 0.3.8.1 requires torch<=2.0.0,>=1.9.0, but you have torch 2.4.0 which is incompatible.\n",
      "autogluon-common 1.0.0 requires pandas<2.2.0,>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n",
      "autogluon-common 1.0.0 requires psutil<6,>=5.7.3, but you have psutil 6.0.0 which is incompatible.\n",
      "fastai 2.7.14 requires torch<2.3,>=1.10, but you have torch 2.4.0 which is incompatible.\n",
      "autogluon-core 1.0.0 requires pandas<2.2.0,>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n",
      "autogluon-tabular 1.0.0 requires pandas<2.2.0,>=2.0.0, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 attrs-23.2.0 certifi-2024.7.4 charset-normalizer-3.3.2 cycler-0.12.1 datasets-2.16.1 dill-0.3.7 fsspec-2023.10.0 idna-3.7 jinja2-3.1.4 kiwisolver-1.4.5 matplotlib-3.4.3 multiprocess-0.70.15 networkx-3.3 numpy-1.26.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 packaging-24.1 psutil-6.0.0 pyparsing-3.1.2 python-dateutil-2.9.0.post0 pyyaml-6.0.1 sentencepiece-0.1.99 six-1.16.0 tokenizers-0.15.2 torch-2.4.0 tqdm-4.65.0 transformers-4.35.2 triton-3.0.0 urllib3-1.26.19\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r SVD-LLM/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]/cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages/transformers/modeling_utils.py:484: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  4.22s/it]\n",
      "Number of params: 6738415616\n",
      "/cephfs/projects/ppashin/SMILES(Vova)/SVD-LLM/SVD-LLM/utils/data_utils.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  traindataset = torch.load(cache_file)\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/cephfs/projects/ppashin/SMILES(Vova)/SVD-LLM/SVD-LLM/SVDLLM.py\", line 529, in <module>\n",
      "    profiling_mat = profle_svdllm_low_resource(args.model, model, cali_white_data, args.DEV)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cephfs/projects/ppashin/SMILES(Vova)/SVD-LLM/SVD-LLM/SVDLLM.py\", line 118, in profle_svdllm_low_resource\n",
      "    model(**batch)\n",
      "  File \"/cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 1034, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py\", line 922, in forward\n",
      "    layer_outputs = decoder_layer(\n",
      "                    ^^^^^^^^^^^^^^\n",
      "  File \"/cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cephfs/projects/ppashin/SMILES(Vova)/SVD-LLM/SVD-LLM/SVDLLM.py\", line 110, in forward\n",
      "    cache['attention_mask'] = torch.cat((cache['attention_mask'], kwargs['attention_mask'].cpu()), dim=0)\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python SVD-LLM/SVDLLM.py --model jeffwan/llama-7b-hf --step 1 --ratio 0.2 --whitening_nsamples 256 --dataset wikitext2 --seed 3 --model_seq_len 2048 --save_path . --DEV cuda:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "evaluating jeffwan_llama_7b_hf_whitening_only_0_8.pt...\n",
      "/cephfs/projects/ppashin/SMILES(Vova)/SVD-LLM/SVD-LLM/utils/model_utils.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pruned_dict = torch.load(model_id, map_location='cpu')\n",
      "Number of params: 5442539520\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/cephfs/projects/ppashin/SMILES(Vova)/SVD-LLM/SVD-LLM/SVDLLM.py\", line 576, in <module>\n",
      "    model = model.half()\n",
      "            ^^^^^^^^^^^^\n",
      "  File \"/cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages/transformers/modeling_utils.py\", line 2281, in half\n",
      "    return super().half(*args)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1012, in half\n",
      "    return self._apply(lambda t: t.half() if t.is_floating_point() else t)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
      "    module._apply(fn)\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"/cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 805, in _apply\n",
      "    param_applied = fn(param)\n",
      "                    ^^^^^^^^^\n",
      "  File \"/cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1012, in <lambda>\n",
      "    return self._apply(lambda t: t.half() if t.is_floating_point() else t)\n",
      "                                 ^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python SVD-LLM/SVDLLM.py --step 5 --model_path jeffwan_llama_7b_hf_whitening_only_0_8.pt --DEV cuda:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'MERA'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 1488, done.\u001b[K\n",
      "remote: Counting objects: 100% (550/550), done.\u001b[K\n",
      "remote: Compressing objects: 100% (394/394), done.\u001b[K\n",
      "remote: Total 1488 (delta 221), reused 362 (delta 153), pack-reused 938\u001b[K\n",
      "Receiving objects: 100% (1488/1488), 8.66 MiB | 7.40 MiB/s, done.\n",
      "Resolving deltas: 100% (616/616), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ai-forever/MERA.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///cephfs/projects/ppashin/SMILES%28Vova%29/SVD-LLM/MERA/lm-evaluation-harness\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from lm_eval==0.3.0) (2.16.1)\n",
      "Collecting einops (from lm_eval==0.3.0)\n",
      "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting jsonlines (from lm_eval==0.3.0)\n",
      "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting numexpr (from lm_eval==0.3.0)\n",
      "  Downloading numexpr-2.10.1.tar.gz (101 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting openai>=0.6.4 (from lm_eval==0.3.0)\n",
      "  Downloading openai-1.38.0-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: omegaconf>=2.2 in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from lm_eval==0.3.0) (2.2.3)\n",
      "Collecting peft>=0.2.0 (from lm_eval==0.3.0)\n",
      "  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pybind11>=2.6.2 (from lm_eval==0.3.0)\n",
      "  Downloading pybind11-2.13.1-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting pycountry (from lm_eval==0.3.0)\n",
      "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pytablewriter (from lm_eval==0.3.0)\n",
      "  Downloading pytablewriter-1.2.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting rouge-score>=0.0.4 (from lm_eval==0.3.0)\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sacrebleu==1.5.0 (from lm_eval==0.3.0)\n",
      "  Downloading sacrebleu-1.5.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.24.1 in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from lm_eval==0.3.0) (1.4.1.post1)\n",
      "Collecting sqlitedict (from lm_eval==0.3.0)\n",
      "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=2.0 in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from lm_eval==0.3.0) (2.4.0)\n",
      "Collecting tqdm-multiprocess (from lm_eval==0.3.0)\n",
      "  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting transformers>=4.36.2 (from lm_eval==0.3.0)\n",
      "  Downloading transformers-4.43.3-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting zstandard (from lm_eval==0.3.0)\n",
      "  Downloading zstandard-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: accelerate>=0.17.1 in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from lm_eval==0.3.0) (0.21.0)\n",
      "Collecting portalocker (from sacrebleu==1.5.0->lm_eval==0.3.0)\n",
      "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from accelerate>=0.17.1->lm_eval==0.3.0) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from accelerate>=0.17.1->lm_eval==0.3.0) (24.1)\n",
      "Requirement already satisfied: psutil in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from accelerate>=0.17.1->lm_eval==0.3.0) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from accelerate>=0.17.1->lm_eval==0.3.0) (6.0.1)\n",
      "Requirement already satisfied: filelock in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from datasets>=2.0.0->lm_eval==0.3.0) (3.9.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from datasets>=2.0.0->lm_eval==0.3.0) (15.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from datasets>=2.0.0->lm_eval==0.3.0) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from datasets>=2.0.0->lm_eval==0.3.0) (0.3.7)\n",
      "Requirement already satisfied: pandas in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from datasets>=2.0.0->lm_eval==0.3.0) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from datasets>=2.0.0->lm_eval==0.3.0) (2.28.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from datasets>=2.0.0->lm_eval==0.3.0) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from datasets>=2.0.0->lm_eval==0.3.0) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from datasets>=2.0.0->lm_eval==0.3.0) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets>=2.0.0->lm_eval==0.3.0) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from datasets>=2.0.0->lm_eval==0.3.0) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from datasets>=2.0.0->lm_eval==0.3.0) (0.21.4)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from omegaconf>=2.2->lm_eval==0.3.0) (4.9.3)\n",
      "Collecting anyio<5,>=3.5.0 (from openai>=0.6.4->lm_eval==0.3.0)\n",
      "  Downloading anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=0.6.4->lm_eval==0.3.0)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai>=0.6.4->lm_eval==0.3.0)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from openai>=0.6.4->lm_eval==0.3.0) (1.10.14)\n",
      "Collecting sniffio (from openai>=0.6.4->lm_eval==0.3.0)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from openai>=0.6.4->lm_eval==0.3.0) (4.8.0)\n",
      "Requirement already satisfied: safetensors in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from peft>=0.2.0->lm_eval==0.3.0) (0.4.2)\n",
      "Requirement already satisfied: absl-py in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from rouge-score>=0.0.4->lm_eval==0.3.0) (2.1.0)\n",
      "Requirement already satisfied: nltk in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from rouge-score>=0.0.4->lm_eval==0.3.0) (3.8.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from rouge-score>=0.0.4->lm_eval==0.3.0) (1.16.0)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn>=0.24.1->lm_eval==0.3.0)\n",
      "  Downloading scipy-1.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn>=0.24.1->lm_eval==0.3.0)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn>=0.24.1->lm_eval==0.3.0)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: sympy in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from torch>=2.0->lm_eval==0.3.0) (1.12)\n",
      "Requirement already satisfied: networkx in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from torch>=2.0->lm_eval==0.3.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from torch>=2.0->lm_eval==0.3.0) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from torch>=2.0->lm_eval==0.3.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from torch>=2.0->lm_eval==0.3.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from torch>=2.0->lm_eval==0.3.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from torch>=2.0->lm_eval==0.3.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from torch>=2.0->lm_eval==0.3.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from torch>=2.0->lm_eval==0.3.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from torch>=2.0->lm_eval==0.3.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from torch>=2.0->lm_eval==0.3.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from torch>=2.0->lm_eval==0.3.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from torch>=2.0->lm_eval==0.3.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from torch>=2.0->lm_eval==0.3.0) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from torch>=2.0->lm_eval==0.3.0) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0->lm_eval==0.3.0) (12.6.20)\n",
      "Collecting huggingface-hub>=0.19.4 (from datasets>=2.0.0->lm_eval==0.3.0)\n",
      "  Downloading huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from transformers>=4.36.2->lm_eval==0.3.0) (2023.12.25)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers>=4.36.2->lm_eval==0.3.0)\n",
      "  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from jsonlines->lm_eval==0.3.0) (23.2.0)\n",
      "Requirement already satisfied: setuptools>=38.3.0 in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from pytablewriter->lm_eval==0.3.0) (60.2.0)\n",
      "Collecting DataProperty<2,>=1.0.1 (from pytablewriter->lm_eval==0.3.0)\n",
      "  Downloading DataProperty-1.0.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm_eval==0.3.0)\n",
      "  Downloading mbstrdecoder-1.1.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm_eval==0.3.0)\n",
      "  Downloading pathvalidate-3.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm_eval==0.3.0)\n",
      "  Downloading tabledata-1.3.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm_eval==0.3.0)\n",
      "  Downloading tcolorpy-0.1.6-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.3.0)\n",
      "  Downloading typepy-1.3.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: colorama in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from tqdm-multiprocess->lm_eval==0.3.0) (0.4.6)\n",
      "Requirement already satisfied: idna>=2.8 in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai>=0.6.4->lm_eval==0.3.0) (3.7)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->lm_eval==0.3.0) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->lm_eval==0.3.0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->lm_eval==0.3.0) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->lm_eval==0.3.0) (1.9.4)\n",
      "Requirement already satisfied: certifi in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=0.6.4->lm_eval==0.3.0) (2024.7.4)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=0.6.4->lm_eval==0.3.0)\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=0.6.4->lm_eval==0.3.0) (0.14.0)\n",
      "Collecting chardet<6,>=3.0.4 (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval==0.3.0)\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.0.0->lm_eval==0.3.0) (3.3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.0.0->lm_eval==0.3.0) (1.26.19)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.3.0) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2018.9 in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.3.0) (2023.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /cephfs/projects/ppashin/SMILES(Vova)/.conda/lib/python3.11/site-packages (from jinja2->torch>=2.0->lm_eval==0.3.0) (2.1.5)\n",
      "Requirement already satisfied: click in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from nltk->rouge-score>=0.0.4->lm_eval==0.3.0) (8.1.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /cephfs/projects/ppashin/.local/lib/python3.11/site-packages (from sympy->torch>=2.0->lm_eval==0.3.0) (1.3.0)\n",
      "Downloading sacrebleu-1.5.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.38.0-py3-none-any.whl (335 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.9/335.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.12.0-py3-none-any.whl (296 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pybind11-2.13.1-py3-none-any.whl (238 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.8/238.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.43.3-py3-none-any.whl (9.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytablewriter-1.2.0-py3-none-any.whl (111 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
      "Downloading zstandard-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading DataProperty-1.0.1-py3-none-any.whl (27 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.24.5-py3-none-any.whl (417 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.5/417.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mbstrdecoder-1.1.3-py3-none-any.whl (7.8 kB)\n",
      "Downloading pathvalidate-3.2.0-py3-none-any.whl (23 kB)\n",
      "Downloading scipy-1.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.1/41.1 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading tabledata-1.3.3-py3-none-any.whl (11 kB)\n",
      "Downloading tcolorpy-0.1.6-py3-none-any.whl (8.1 kB)\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading typepy-1.3.2-py3-none-any.whl (31 kB)\n",
      "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: lm_eval, rouge-score, numexpr, sqlitedict\n",
      "  Building editable for lm_eval (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lm_eval: filename=lm_eval-0.3.0-0.editable-py3-none-any.whl size=5405 sha256=4db93900130f8dbbc6903b71c3c98e7f18c808033f3b61e55be7c4beb6585e36\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-9nahbo99/wheels/df/76/21/7699b2b1c8590b8cbcdb32698067c15e74415e417c798954b2\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24951 sha256=edda56504a04d81dfa388653a1a940107cb5fd0bf70d8a56f79ac43c7a8e8938\n",
      "  Stored in directory: /cephfs/projects/ppashin/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "  Building wheel for numexpr (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for numexpr: filename=numexpr-2.10.1-cp311-cp311-linux_x86_64.whl size=146185 sha256=9f55c7a27955269e0f58377abc3b951c524f0069a7301ab766484f2e8a2e8ab2\n",
      "  Stored in directory: /cephfs/projects/ppashin/.cache/pip/wheels/95/8f/06/86d86d1afaa270e49bedb56c85c6ffd48d8eccdb9f678e55e4\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16869 sha256=7238c888efc733a236d92737e11ee769ebf681eec682cf51f788ac63c495f254\n",
      "  Stored in directory: /cephfs/projects/ppashin/.cache/pip/wheels/73/63/89/7210274f9b7fb033b8f22671f64c0e0b55083d30c3c046a3ff\n",
      "Successfully built lm_eval rouge-score numexpr sqlitedict\n",
      "Installing collected packages: sqlitedict, zstandard, tqdm-multiprocess, threadpoolctl, tcolorpy, sniffio, scipy, pycountry, pybind11, portalocker, pathvalidate, numexpr, jsonlines, joblib, httpcore, einops, distro, chardet, sacrebleu, mbstrdecoder, huggingface-hub, anyio, typepy, tokenizers, rouge-score, httpx, transformers, openai, peft, DataProperty, tabledata, pytablewriter, lm_eval\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.21.4\n",
      "    Uninstalling huggingface-hub-0.21.4:\n",
      "      Successfully uninstalled huggingface-hub-0.21.4\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.15.2\n",
      "    Uninstalling tokenizers-0.15.2:\n",
      "      Successfully uninstalled tokenizers-0.15.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.35.2\n",
      "    Uninstalling transformers-4.35.2:\n",
      "      Successfully uninstalled transformers-4.35.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 1.0.0 requires defusedxml<0.7.2,>=0.7.1, which is not installed.\n",
      "autogluon-multimodal 1.0.0 requires jsonschema<4.18,>=4.14, which is not installed.\n",
      "lightning 2.0.9.post0 requires beautifulsoup4<6.0,>=4.8.0, which is not installed.\n",
      "lightning 2.0.9.post0 requires websocket-client<3.0, which is not installed.\n",
      "autowoe 1.3.2 requires seaborn, which is not installed.\n",
      "lightautoml 0.3.8.1 requires seaborn, which is not installed.\n",
      "autogluon-features 1.0.0 requires pandas<2.2.0,>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n",
      "autogluon-multimodal 1.0.0 requires pandas<2.2.0,>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n",
      "autogluon-multimodal 1.0.0 requires scipy<1.13,>=1.5.4, but you have scipy 1.14.0 which is incompatible.\n",
      "autogluon-multimodal 1.0.0 requires torch<2.1,>=2.0, but you have torch 2.4.0 which is incompatible.\n",
      "autogluon-multimodal 1.0.0 requires transformers[sentencepiece]<4.32.0,>=4.31.0, but you have transformers 4.43.3 which is incompatible.\n",
      "autogluon-timeseries 1.0.0 requires pandas<2.2.0,>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n",
      "autogluon-timeseries 1.0.0 requires scipy<1.13,>=1.5.4, but you have scipy 1.14.0 which is incompatible.\n",
      "autogluon-timeseries 1.0.0 requires torch<2.1,>=2.0, but you have torch 2.4.0 which is incompatible.\n",
      "lightautoml 0.3.8.1 requires joblib<1.3.0, but you have joblib 1.4.2 which is incompatible.\n",
      "lightautoml 0.3.8.1 requires torch<=2.0.0,>=1.9.0, but you have torch 2.4.0 which is incompatible.\n",
      "fastai 2.7.14 requires torch<2.3,>=1.10, but you have torch 2.4.0 which is incompatible.\n",
      "autogluon-core 1.0.0 requires pandas<2.2.0,>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n",
      "autogluon-core 1.0.0 requires scipy<1.13,>=1.5.4, but you have scipy 1.14.0 which is incompatible.\n",
      "autogluon-tabular 1.0.0 requires pandas<2.2.0,>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n",
      "autogluon-tabular 1.0.0 requires scipy<1.13,>=1.5.4, but you have scipy 1.14.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed DataProperty-1.0.1 anyio-4.4.0 chardet-5.2.0 distro-1.9.0 einops-0.8.0 httpcore-1.0.5 httpx-0.27.0 huggingface-hub-0.24.5 joblib-1.4.2 jsonlines-4.0.0 lm_eval-0.3.0 mbstrdecoder-1.1.3 numexpr-2.10.1 openai-1.38.0 pathvalidate-3.2.0 peft-0.12.0 portalocker-2.10.1 pybind11-2.13.1 pycountry-24.6.1 pytablewriter-1.2.0 rouge-score-0.1.2 sacrebleu-1.5.0 scipy-1.14.0 sniffio-1.3.1 sqlitedict-2.1.0 tabledata-1.3.3 tcolorpy-0.1.6 threadpoolctl-3.5.0 tokenizers-0.19.1 tqdm-multiprocess-0.0.11 transformers-4.43.3 typepy-1.3.2 zstandard-0.23.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -e MERA/lm-evaluation-harness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Tasks: ['ruhumaneval']\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:00<00:00,  4.89it/s]\n",
      "Using `model.prepare_inputs_for_generation` method for `model.forward`.\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "Searching for good max length. OOM at length 11500\n",
      "Searching for good max length. OOM at length 5800\n",
      "Searching for good max length. OOM at length 2949\n",
      "length 1524 not failed but it can be lengthier\n",
      "length 2236 not failed but it can be lengthier\n",
      "length 2592 not failed but it can be lengthier\n",
      "length 2770 not failed but it can be lengthier\n",
      "Searching for good max length. OOM at length 2859\n",
      "2814 is good enough\n",
      "Downloading readme: 100%|█████████████████████| 137k/137k [00:00<00:00, 600kB/s]\n",
      "Downloading data: 100%|███████████████████████| 614k/614k [00:00<00:00, 991kB/s]\n",
      "Downloading data: 100%|██████████████████████| 254k/254k [00:00<00:00, 1.47MB/s]\n",
      "Generating public_test split: 100%|██| 164/164 [00:00<00:00, 6498.68 examples/s]\n",
      "Generating test split: 100%|████████| 164/164 [00:00<00:00, 22856.48 examples/s]\n",
      "Task: ruhumaneval; number of docs: 164\n",
      "Running ruhumaneval requests\n",
      "  4%|█▌                                       | 6/164 [02:33<1:08:21, 25.96s/it]"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=3 python MERA/lm-evaluation-harness/main.py --model hf-causal-experimental --model_args pretrained=mistralai/Mistral-7B-v0.1,dtype=auto,max_length=11500 \\\n",
    "--device cuda --output_base_path=\"$PWD/mera_results/Mistral-7B-v0.1_defaults\" --batch_size=1 \\\n",
    "--inference --write_out --no_cache --tasks ruhumaneval --num_fewshot=5 \\\n",
    "--output_path=\"$PWD/mera_results/Mistral-7B-v0.1_defaults/ruhumaneval_result.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
